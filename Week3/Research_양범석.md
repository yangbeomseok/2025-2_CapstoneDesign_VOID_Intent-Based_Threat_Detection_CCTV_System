# CRxK 논문 분석 및 프로젝트 적용 방안

**문서 목적**: CRxK 논문의 데이터셋 구축 방법론을 분석하고, 이를 바탕으로 우리 **행동 의도 기반 위험 탐지 CCTV 시스템** 프로젝트의 핵심 데이터셋인 **3-Class(정상, 의심, 범죄) 스켈레톤 데이터셋** 구축 전략을 수립한다.

---

## 1. CRxK 데이터셋 구축 워크플로우 분석

성균관대학교 연구팀은 **이미지 프레임 기반**의 CRxK-6 모델 설계를 위해 AI Hub 데이터를 활용했으며, 그 과정은 다음과 같다.

### 1.1. 데이터 소스 및 기본 전처리
- **데이터 소스**: AI Hub의 '이상행동 CCTV 영상'과 함께 제공되는 **어노테이션 파일(Annotation File)** 을 원본으로 사용한다.
- **초기 전처리**: 영상 속 인물의 얼굴을 **페이스 마스킹(Face-Masking)** 처리하여 익명화한다.

### 1.2. 영상 클리핑 및 프레임 추출
- **영상 클리핑**: 어노테이션 파일에 명시된 시간을 기준으로 **'범죄'** 와 **'정상'** 구간의 영상 클립을 추출한다.
- **프레임 추출 및 변환**: 클리핑된 영상에서 **초당 15프레임(15fps)** 으로 이미지를 추출하고, **256x256 픽셀** 크기로 변환하여 약 205만 개의 이미지 데이터 풀을 생성한다.

### 1.3. 최종 학습 데이터셋 구축
- **데이터 불균형 해결 (언더샘플링)**: 클래스 간 불균형 문제를 해결하기 위해, 각 카테고리에서 **8,500개의 프레임을 무작위로 동일하게 추출**하여 총 **51,000개**의 균형 잡힌 이미지 데이터셋을 구축한다.
- **학습/테스트 분할**: **1:40** 비율로 데이터를 분할하여, 적은 데이터 환경에서의 모델 강인성을 평가한다.

---

## 2. 우리 프로젝트 적용 방안: 스켈레톤 기반 3-Class 데이터셋 설계

> CRxK 논문은 '정상'과 '범죄'를 **이미지 기반으로 분류**하는 것이 목표였다. 하지만 우리 프로젝트는 **스켈레톤 데이터**를 활용하여 **'의심 행동'을 사전에 탐지**하는 것을 목표로 하므로, 데이터 처리 파이프라인과 최종 데이터 형태 모두에서 차별점을 가진다.

### 2.1. 핵심 전처리: 스켈레톤 추출 및 데이터 구조화
- **스켈레톤 추출 (Pose Estimation)**: 원본 영상 전체에 대해 **MediaPipe** 또는 **OpenPose** 같은 포즈 추정 모델을 먼저 적용하여, 영상 속 모든 사람의 **주요 관절 좌표(스켈레톤 데이터)** 를 추출한다. 이 시점부터 우리는 **이미지(JPG)가 아닌 좌표 데이터(JSON 등)를 다루게 된다.**
- **프라이버시 강화**: 이 방식은 원본 영상 자체를 저장하거나 학습에 사용하지 않고 비식별화된 스켈레톤 정보만 활용하므로, 페이스 마스킹보다 한 차원 높은 수준의 **프라이버시 보호**를 보장한다.

### 2.2. 데이터셋 재정의: 3-Class 스켈레톤 시퀀스
어노테이션 파일의 시간 정보를 기준으로, 추출된 전체 스켈레톤 데이터 스트림에서 다음 세 가지 클래스에 해당하는 **스켈레톤 시퀀스(sequence)** 를 잘라낸다.

- **정상 (Normal)**: 범죄와 무관한 일상적 행동 패턴을 담은 스켈레톤 데이터 시퀀스.
- **의심 (Suspicious)**: 범죄 발생 직전의 전조 행동(배회, 접근 등)에 해당하는 스켈레톤 데이터 시퀀스.
- **범죄 (Crime)**: 실제 범죄 행위의 동적 패턴을 담은 스켈레톤 데이터 시퀀스.

### 2.3. 클리핑 규칙 예시
1분짜리 영상에서 **20초**에 범죄가 시작된다면, 전체 영상에서 추출된 스켈레톤 데이터 스트림을 다음과 같이 분할한다.

- **`0초 ~ 10초` 구간의 스켈레톤 데이터**: **정상 (Normal)** 시퀀스로 저장.
- **`15초 ~ 20초` 구간의 스켈레톤 데이터**: **의심 (Suspicious)** 시퀀스로 저장.
- **`20초 ~ 범죄 종료 시점`의 스켈레톤 데이터**: **범죄 (Crime)** 시퀀스로 저장.

이러한 접근은 우리 모델이 이미지의 시각적 특징이 아닌, **시간에 따른 인체의 미세한 움직임과 동선 패턴(시계열 데이터)** 을 학습하여 행동의 '의도'를 예측하도록 만든다.

---

## 3. 결론 및 최종 전략

**성균관대학교의 CRxK 연구는 우리 프로젝트의 데이터셋 구축에 있어 매우 훌륭한 청사진을 제공한다.**

우리는 CRxK 논문의 데이터 분석 및 샘플링 방법론을 적극적으로 활용하되, 다음과 같은 **두 가지 핵심적인 차별점**을 통해 프로젝트의 독창성을 확보한다.

1.  **데이터 형태의 차별화**: 이미지(JPG)가 아닌 **스켈레톤(좌표 시퀀스)** 데이터를 사용하여 프라이버시를 극대화하고, 행동의 동적 패턴에 집중한다.
2.  **데이터 클래스의 차별화**: '정상'과 '범죄'의 2-Class 분류를 넘어, **'의심' 클래스를 추가한 3-Class 데이터셋**을 구축하여 범죄를 사전에 예측하는 것을 목표로 한다.


# 3. 공개 데이터셋 목록 및 특성 분석

| 데이터셋명      | 특성                                     | 활용 방안                          | 출처             |
|---------------|----------------------------------------|-----------------------------------|----------------|
| [CRxK](https://github.com/dxlabskku/CRxK-6)    | 6개 범죄 유형, 총 51,000 프레임 샘플링[1]  | 핵심 범죄 행동 프레임 학습         | Sci. Rep. 2025[1] |
| [AI Hub 이상행동](https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=data&dataSetSn=171) | 8,436편(717시간), 12개 이상행동 라벨[61]   | 정상 vs 의심 행동 이진 분류        | AI Hub[61]      |
| HR-Crime  | UCF-Crime 데이터의 단점을 보완하여 정제 | 이상행동 탐지 일반화 성능 검증    | UCSB CV Lab[3]  |
| [UNI-Crime](https://link.springer.com/chapter/10.1007/978-3-030-19823-7_23) | HR-Crime과 마찬가지, 10초 길이로 정제 후 유튜브 영상을 추가 수집, 1001개의 정상 420개의 범죄 | 이상행동 탐지 일반화 성능 검증 | Sci. Rep. 2025[1] |
| [XD-Violence](https://roc-ng.github.io/XD-Violence/)   | 4,000편 폭력·위협 행동 비디오             | 폭력·위협 세부 분류                | Bilibili AI[4]  |
| [ShanghaiTech](https://svip-lab.github.io/dataset/campus_dataset.html)  | 13개 장면, 이상행동 라벨                  | 이상행동(Anomaly) 탐지            | SJTU[5]         |
| [VIRAT](https://gitlab.kitware.com/viratdata/viratannotations)         | 10시간 이상 공공장소 활동·침입 라벨       | 이동 및 침입 이벤트 감지          | NIST[6]         |
| [Avenue](https://www.cse.cuhk.edu.hk/leojia/projects/detectabnormal/dataset.html)        | 16편 영상, 1,561 이상행동 이벤트          | 군중 이상행동 분석                | UCSD[7]         |

# Week3_행동 의도 탐지에 적합한 딥러닝 모델 아키텍처 조사 및 활용 가능한 공개 데이터셋 목록 정리 및 특성 분석

**문서 목적**: 행동 의도 및 이상행동 탐지 분야의 주요 데이터셋과 딥러닝 모델 아키텍처를 분석하여, 우리 **행동 의도 기반 위험 탐지 CCTV 시스템** 프로젝트의 기술적 토대를 마련하고 최종 데이터셋 구축 및 모델링 전략을 수립한다.

---

## 1. 활용 가능한 공개 데이터셋 목록 정리 및 특성 분석

우리 프로젝트의 **3-Class(정상, 의심, 범죄) 스켈레톤 데이터셋** 구축 및 모델 성능 검증을 위해 다음과 같은 데이터셋들을 활용할 수 있다.  
**상위 3가지의 데이터셋을 메인으로 사용한다.**

| 데이터셋명 | 주요 특징 | 우리 프로젝트 활용 방안 | 원본 링크 |
| :--- | :--- | :--- | :--- |
| **[AI Hub 이상행동](https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=data&dataSetSn=171)** | 8,436편(717시간), 12개 이상행동 라벨 및 **시간 주석** 포함. | **메인 데이터셋**. '정상-의심-범죄' 클래스 분할의 핵심 소스. | [AI Hub](https://aihub.or.kr/aihubdata/data/view.do?dataSetSn=171) |
| **UCA / UCF-Crime** | 대규모(1,854개 영상), 13개 범죄 유형. **UCA**는 UCF의 주석을 더 정밀하게 작업한 버전. 단, **화질이 낮아 업샘플링 기법 적용 고려 필요**. | AI Hub에 없는 범죄 유형 추가 및 모델 일반화 성능 검증. | [UCF-Official](https://www.crcv.ucf.edu/projects/real-world/) / [UCA](https://www.kaggle.com/datasets/vigneshwar472/ucaucf-crime-annotation-dataset) / [w. BBox](https://www.kaggle.com/datasets/vulamnguyen/ucfcrime2local-with-ground-truth-bounding-boxes) |
| **[Real Life Violence Situations](https://www.kaggle.com/datasets/mohamedmustafa/real-life-violence-situations-dataset)** | **비폭력(NonViolence) 영상 1,000개**(식사, 스포츠 등)와 폭력 영상 1,000개로 구성. | AI Hub 데이터만으로 부족할 수 있는 **'정상(Normal)' 클래스 데이터 보강**에 적극 활용. | [Kaggle](https://www.kaggle.com/datasets/mohamedmustafa/real-life-violence-situations-dataset) |
| **[PoseLift Dataset](https://github.com/TeCSAR-UNCC/PoseLift)** | 상점털이 데이터셋. **2D 스켈레톤을 3D로 변환하는 모델** 포함 (17개 관절). | 2D 기반 모델의 성능 한계 봉착 시, **3D 스켈레톤으로 확장**하기 위한 핵심 모델. | [GitHub](https://github.com/TeCSAR-UNCC/PoseLift) |
| **[RWF-2000](https://github.com/mchengny/RWF2000-Video-Database-for-Violence-Detection)** | 실제 CCTV와 유사한 환경에서 촬영된 폭력/비폭력 영상 2,000개. | 모델의 **실환경 강인성(Robustness) 테스트** 및 평가. | [GitHub](https://github.com/mchengny/RWF2000-Video-Database-for-Violence-Detection) |
| **[XD-Violence](https://roc-ng.github.io/XD-Violence/)** | 4,000편 이상의 폭력·위협 행동 비디오. | '범죄' 클래스를 더 세분화하거나, 폭력 행위 탐지 성능 고도화. | [GitHub](https://github.com/Roc-Ng/XDVioDet/tree/master) |
| **[Campus Crime (CCD)](https://svip-lab.github.io/dataset/campus_dataset.html)** | 대학 캠퍼스 환경의 8가지 시점에서 촬영된 1,847개 비디오 클립. | 특정 도메인(캠퍼스)에서의 모델 성능 평가 및 미세 조정(fine-tuning). | [Project Page](https://svip-lab.github.io/dataset/campus_dataset.html) |
| **[VIoPeru](https://github.com/hhuillcen/VioPeru/tree/main/train)** | 7,163개의 짧은 비디오 클립. | 다양한 폭력/비폭력 상황 데이터 추가 확보. | [GitHub](https://github.com/hhuillcen/VioPeru/tree/main/train) |

---

## 2. 프로젝트 전략 수립을 위한 CRxK 논문 분석

### 2.1. CRxK 데이터셋 구축 워크플로우 분석
성균관대학교 연구팀은 **이미지 프레임 기반**의 CRxK-6 모델 설계를 위해 AI Hub 데이터를 활용했으며, 그 과정은 다음과 같다.

- **데이터 소스**: AI Hub의 '이상행동 CCTV 영상'과 함께 제공되는 **어노테이션 파일(Annotation File)** 을 원본으로 사용한다.
- **초기 전처리**: 영상 속 인물의 얼굴을 **페이스 마스킹(Face-Masking)** 처리하여 익명화한다. 허나, 우리는 스켈레톤 기법을 사용할 것이기 때문에 초기 전처리 과정은 생략해도 괜찮을 것으로 보인다. 
- **영상 클리핑 및 프레임 추출**: 어노테이션 파일에 명시된 시간을 기준으로 **'범죄'** 와 **'정상'** 구간의 영상 클립을 추출한다.
- **프레임 추출 및 변환**: 클리핑된 영상에서 **초당 15프레임(15fps)** 으로 이미지를 추출하고, **256x256 픽셀** 크기로 변환하여 약 205만 개의 이미지 데이터 풀을 생성한다.
- **최종 학습 데이터셋 구축 (언더샘플링)**: 클래스 간 불균형 문제를 해결하기 위해, 각 카테고리에서 **8,500개의 프레임을 완전 무작위로 동일하게 추출**하여 총 **51,000개**의 균형 잡힌 이미지 데이터셋을 구축한다. 이때 각 영상 간 프레임 비율은 신경 쓰지 않는다.
- **학습/테스트 분할**: **1:40** 비율로 데이터를 분할하여, 적은 데이터 환경에서의 모델 강인성을 평가한다.

### 2.2. 우리 프로젝트 적용 방안: 스켈레톤 기반 3-Class 데이터셋 설계
> CRxK 논문은 '정상'과 '범죄'를 **이미지 기반으로 분류**하는 것이 목표였다. 하지만 우리 프로젝트는 **스켈레톤 데이터**를 활용하여 **'의심 행동'을 사전에 탐지**하는 것을 목표로 하므로, 데이터 처리 파이프라인과 최종 데이터 형태 모두에서 차별점을 가진다.

- **핵심 전처리: 스켈레톤 추출 및 데이터 구조화**
    - **객체 탐지**: **OpenCV**로 원본 영상을 읽고 **YOLO**와 같은 객체 탐지 모델로 바운딩 박스를 쳐서 사람의 위치를 먼저 찾는다.
    - **스켈레톤 추출 (Pose Estimation)**: 탐지된 사람 영역에 **MediaPipe** 또는 **OpenPose** 같은 포즈 추정 모델을 먼저 적용하여, 영상 속 모든 사람의 **주요 관절 좌표(스켈레톤 데이터)** 를 추출한다. 이 시점부터 우리는 **이미지(JPG)가 아닌 좌표 데이터(JSON 등)를 다루게 된다.**
    - **프라이버시 강화**: 이 방식은 원본 영상 자체를 저장하거나 학습에 사용하지 않고 비식별화된 스켈레톤 정보만 활용하므로, 페이스 마스킹보다 한 차원 높은 수준의 **프라이버시 보호**를 보장한다.

- **데이터셋 재정의: 3-Class 스켈레톤 시퀀스**
    어노테이션 파일의 시간 정보를 기준으로, 추출된 전체 스켈레톤 데이터 스트림에서 다음 세 가지 클래스에 해당하는 **스켈레톤 시퀀스(sequence)** 를 잘라낸다.
    - **정상 (Normal)**: 범죄와 무관한 일상적 행동 패턴을 담은 스켈레톤 데이터 시퀀스.
    - **의심 (Suspicious)**: 범죄 발생 직전의 전조 행동(배회, 접근 등)에 해당하는 스켈레톤 데이터 시퀀스.
    - **범죄 (Crime)**: 실제 범죄 행위의 동적 패턴을 담은 스켈레톤 데이터 시퀀스.

- **클리핑 규칙 예시**
    1분짜리 영상에서 **20초**에 범죄가 시작된다면, 전체 영상에서 추출된 스켈레톤 데이터 스트림을 다음과 같이 분할한다.
    - **`0초 ~ 10초` 구간의 스켈레톤 데이터**: **정상 (Normal)** 시퀀스로 저장.
    - **`15초 ~ 20초` 구간의 스켈레톤 데이터**: **의심 (Suspicious)** 시퀀스로 저장.
    - **`20초 ~ 범죄 종료 시점`의 스켈레톤 데이터**: **범죄 (Crime)** 시퀀스로 저장.

> 이러한 접근은 우리 모델이 이미지의 시각적 특징이 아닌, **시간에 따른 인체의 미세한 움직임과 동선 패턴(시계열 데이터)** 을 학습하여 행동의 '의도'를 예측하도록 만든다.

---

## 3. 행동 의도 탐지를 위한 모델링 및 개발 전략

### 3.1. 2단계 접근 방식 (Two-Stage Approach)
프로젝트의 효율적인 개발 및 검증을 위해, 다음과 같은 2단계 접근 방식을 채택한다.

#### 1단계: 2D 스켈레톤 기반 MVP 모델 개발
- **목표**: 가장 핵심적인 기능(정상, 의심, 범죄 분류)을 신속하게 구현하고, 데이터 처리 파이프라인의 문제점을 조기에 파악한다.
- **처리 방식**:
    1. **OpenCV**를 사용하여 원본 영상을 프레임 단위로 읽어온다. 각 프레임마다 **YOLO**와 같은 고속 객체 탐지 모델을 적용하여 영상 속 모든 사람의 위치를 바운딩 박스(Bounding Box)로 신속하게 탐지한다.
    2. 탐지된 각 사람의 바운딩 박스 영역을 잘라내어 **MediaPipe** 등 경량화된 포즈 추정 모델의 입력으로 사용한다. 이를 통해 각 인물의 **2D 스켈레톤(x, y 좌표)** 데이터를 정밀하게 추출한다.
    3. 추출된 2D 스켈레톤 시퀀스를 기반으로 **[2D CNN + 1D CNN/RNN]** 하이브리드 모델 학습을 진행한다. 이때 공간 특징 추출을 위한 2D CNN으로는 **CRxK 논문에서 높은 성능을 보인 ResNet18을 우선적으로 검토**한다.
- **기대 효과**: 빠른 프로토타이핑을 통해 프로젝트의 전체적인 방향성과 실현 가능성을 검증할 수 있다.

#### 2단계: 3D 스켈레톤 기반 모델 성능 고도화
- **전환 조건**: 2D 기반 모델의 성능이 목표치에 미치지 못하거나, 특정 행동(예: 단순 접근과 공격적 접근)을 구분하는 데 명확한 한계를 보일 경우 3D 모델로 전환한다.
- **처리 방식**:
    1. **[PoseLift](https://github.com/TeCSAR-UNCC/PoseLift)** 모델을 활용하여, 기존에 추출한 2D 스켈레톤 데이터를 **3D 스켈레톤(x, y, z 좌표)** 으로 확장한다.
    2. Z축(깊이) 정보가 추가된 3D 데이터를 사용하여 모델을 재학습시켜, 더 입체적이고 정밀한 행동 분석을 시도한다.
- **기대 효과**: 더 풍부한 공간 정보를 활용하여 모델의 정확성과 강인성(Robustness)을 한 단계 끌어올릴 수 있다.

---

## 4. 결론 및 최종 전략

**성균관대학교의 CRxK 연구는 우리 프로젝트의 데이터셋 구축에 있어 매우 훌륭한 청사진을 제공한다.**

우리는 CRxK 논문의 데이터 분석 및 샘플링 방법론을 적극적으로 활용하되, 다음과 같은 **두 가지 핵심적인 차별점**을 통해 프로젝트의 독창성을 확보한다.

1.  **데이터 형태의 차별화**: 이미지(JPG)가 아닌 **스켈레톤(좌표 시퀀스)** 데이터를 사용하여 프라이버시를 극대화하고, 행동의 동적 패턴에 집중한다.
2.  **데이터 클래스의 차별화**: '정상'과 '범죄'의 2-Class 분류를 넘어, **'의심' 클래스를 추가한 3-Class 데이터셋**을 구축하여 범죄를 사전에 예측하는 것을 목표로 한다.

---

## 세줄 요약

1.  **데이터**: 메인 요리는 **AI Hub**, **UCA/UCF-Crime**으로 추가적 범죄 영상, **Real Life Violence Situations**와 **AI Hub** 클리핑으로 정상 데이터를 추가. 

2.  **국밥 모델**: CRxK 논문에서 성능이 검증된 **국밥 ResNet18**을 우리 스켈레톤 데이터에 맞게 커스텀.

3.  **스켈레톤**: 만약 2D 스켈레톤의 성능이 아쉽다면 **PoseLift** 모델로 3D 차원 상승.
